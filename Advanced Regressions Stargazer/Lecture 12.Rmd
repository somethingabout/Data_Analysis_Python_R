---
title: 'Lecture 12: Advanced Regressions & Stargazer Continued'
output:
  html_document:
    df_print: paged
  pdf_document: default
---
### We're going to cover:

Regression related:

- Panel (Fixed and Random Effects)
- Logit
- Margins
- one more stargazer

# Advanced Regressions

## Panel Data

There are a few packages out there that implement panel data models. We'll cover two of them, plm() - an older frequently used package, and a newer package, fixest(). Another package to note is [lfe](https://cran.r-project.org/web/packages/lfe/index.html). 


### Fixed Effects Models


Fixed effects models are equivalent to including dummy variables for the entity that you are following over time. You can include these dummy variables as factors (either for time or entity). However, that is computationally inefficient if you have some 1,500 people, for example. So, instead, we use the within transformation. 

In plm() is an option for "within" - that is the fixed effects model. This is because you are taking differences within an entity.  

Let's use world bank data to apply the fixed effects model.

```{r}
library(WDI)
library(tidyverse)

setwd("/Users/mkaltenberg/Documents/GitHub/Data_Analysis_Python_R/Advanced Regressions Stargazer/")

wdi <- WDI(country = "all", start=2000, end=2020, extra="TRUE",
           indicator=c("NY.GDP.MKTP.KD.ZG","SL.TLF.CACT.FE.ZS","SP.POP.TOTL", "SE.PRM.CUAT.ZS" ))
```

Let's quickly clean this up a bit by renaming the columns. I'm going to leave in unnecessary columns since the data is not very large, but if I was working with a large dataframe, I'd drop it.

```{r}
wdi <-rename(wdi,gdp= NY.GDP.MKTP.KD.ZG, lfpart_f= SL.TLF.CACT.FE.ZS, pop= SP.POP.TOTL, edu = SE.PRM.CUAT.ZS)

names(wdi)
```

Let's great a baseline model regression with OLS:
```{r}
ols <- lm(gdp~edu + log(pop), data=wdi)
```



Now, let's run our model.


We need to tell plm what entity is being followed and what is the variable for time using the option index, and we need to tell plm what kind of model we are running. 

Typically, the function is a class of regression methods and there will be an option for a specific estimation method and model.  plm can be considered a package for panel data models and the estimation method is "within"

A one-way fixed effects model is like this:
```{r}
library(plm)
fixed <- plm(gdp~  edu + log(pop) , data=wdi, index = c("iso2c"), model="within")

summary(fixed)

#equivalent in stata:
#xtset iso2c year
#xtreg gdp edu lnpop, fe

```

But, we can include fixed effects for time, too. We just need to include it in the index.
Two ways to do this:
```{r}
library(stargazer)
fixed_tw <- plm(gdp~ edu + log(pop) , data=wdi, index = c("iso2c", "year"), effect = "twoways")

fixed <- plm(gdp~ edu + log(pop) + factor(year) , data=wdi, index = c("iso2c"), model="within")


stargazer(fixed,fixed_tw, type='text')
```

We can see the number of observations (N), the number of groups (n), how many units you have over time (T). 


If you want to see the fixedeffects estimtates, you can do this with `fixef()`

```{r}
fixef(fixed)
```
### fixest
You can run the same above regression with the package fixest using the function feols(). I'm mentioning this particular package because it is *insanely* fast. It can handle a huge amount of fixed effects where stata might break (unless you use reghdfe). It can support non-linear models, high-dimensional fixed effects, multiway clustering and a bunch of options that come in handy when you work with detailed data or big data.  So, I want you to know it exists because of it's flexibility in all things fixed effects.

Let's try it. Rather than setting the fixed effects with an index, you'll include the variables that are fixed after `|` 

Let's see what I mean here:

```{r}
library(fixest)

fixed_est = feols(gdp~  edu + log(pop) | iso2c + year, data = wdi)  ## Fixed effect(s) go after the "|"
fixed_est
```
Standard errors are already clustered by country automatically, but if you want standard errors, you can do so using summary and the option se

```{r}
summary(fixed_est, se = 'standard')
```

There might be time where you want to cluster your standard errors with specific items. You can also specify what you would like to cluster with the option cluster
```{r}

summary(fixed_est, cluster = c('iso2c'))

```

### Random Effects Models

For plm, changing to a random effect model is pretty simple. You just need to change the option "model" to "random"


```{r}
re <- plm(gdp~edu + log(pop) + factor(year), data=wdi, index = c("iso2c"), model="random")
summary(re)
```


There is something else called a mixed model where you might have both fixed effects and random effect parameters. This is particularly useful for nested datasets and when you might want to include fixed effects at one level and random effects for another variable. I've rarely seen it in economics papers, but it is often included in psychology models.  I won't discuss this indepthly, but [here](https://m-clark.github.io/mixed-models-with-R/introduction.html) is a website that explains how to apply it in R - although there are many out there and often people use the package [lmer()](https://rstudio-pubs-static.s3.amazonaws.com/63556_e35cc7e2dfb54a5bb551f3fa4b3ec4ae.html). 

#### Hausman Taylor test

You may know that when deciding between random or fixed effects models, you have to ensure that the random variables do not correlate with your independent variables. Frequently, this assumption is broken and is why most people use fixed effects models.  However, we often want to test between our fixed or random effect model. We do this with the `phtest()` function in plm.

```{r}
fe <- plm(gdp ~ edu +log(pop) +factor(year) , data=wdi, index = c("iso2c"), model="within")

summary(fe)

phtest(fe, re)
```

There are a variety of tests for serial correlation, heteroskedasticity, random effects (if you should include random effects compared to an ols model, stationarity/unit roots, etc). These are outlined in the vignettes of plm and you can explore them further on your own. 

## Logit/Probit

Logit/probit models can be run using the generalized linear model packages `glm()`  You identify a logit or probit model using the option "family".  You need to specify the link function to distinguish between a logit or probit model.

A good introduction to logit models (and many other applied econometric models) can be found at UCLA's website [here](https://stats.idre.ucla.edu/r/dae/logit-regression/) and for probit models [here](https://stats.idre.ucla.edu/r/dae/probit-regression/)

Let's start with a logit model:
```{r}

setwd("/Users/mkaltenberg/Documents/GitHub/Data_Analysis_Python_R/Advanced Regressions Stargazer/")
smoking <- read.csv("smoking.csv")
names(smoking)

logit <- glm(smoker ~ age + female + hsdrop +hsgrad +colsome +colgrad, data = smoking, family = "binomial")
summary(logit)
```

The probit model just needs a tweak in the link function within the option "family", and that is set like this:

```{r}
probit <- glm(smoker ~ age + female + hsdrop +hsgrad +colsome +colgrad, data = smoking, family = binomial(link = "probit"))
summary(probit)
```

Marginal effects can't be read directly from the output. You need to apply the link function to interpret the results (though the sign and standard error can be interpreted as usual). 

This is why the margins function is so important!  Margins works with other regressions, as well. 

## Margins
The margins package is quite similar to the margins package in STATA. You can apply interpretation to a wide variety of regressions - logit/probit, but also non-linear terms in OLS models. You can check out more examples and features in its vignette [here](https://cran.r-project.org/web/packages/margins/vignettes/Introduction.html).


The package makes it easy to calculate values and plot them. 

When we use `margins(model_name)`  it will give us the *average* marginal effect for each variable

```{r}
library(margins)

logit_m <-margins(logit)
```
And we can plot it quit easily:
```{r}
plot(logit_m)
```

To get the partial effect at the mean (or at any particular value), we us the at option:

Here we specify a range of numbers
```{r}
logit_range <-margins(logit, at = list(age = c(18,40,60)), variables = "age")
summary(logit_range)

```

Or at the mean of age
```{r}

mean_age = mean(smoking$age, na.rm=TRUE)

logit_m <- margins(logit, at = list(age = c(mean(smoking$age, na.rm=TRUE))), variables = "age")

summary(logit_m)

```

### Marignal effects for non-linear terms in OLS

The margins package can also be used to get the marginal effects for non-linear terms in OLS models - often these are interactions or polynomial functions.  Let's take an example of a model with the squared term population.

Notice that to square a term I use "^2" and the "I()" to indicate that it's a second order term.

```{r}

int <- lm(gdp ~ lfpart_f + pop + I(pop^2), data = wdi)
summary(int)
```

Let's apply marginal effect to population. We can take the marginal effect of any particular value of population that we are interested in.
```{r}
# in python wdi['pop']

m_pop <- mean(wdi$pop, na.rm=TRUE)  # getting the mean of population

int_ape <- margins(int, at = list(pop =m_pop), variables= "pop") 
summary(int_ape)
```

We can combine those two lines of code into one (and not save the value of the mean of population that will take up RAM)

```{r}
int_ape <-margins(int, at = list(pop = mean(wdi$pop, na.rm=TRUE)))
summary(int_ape)
```

We can input a list of values rather than just one value

```{r}
int_ape <- margins(int, at = list(pop = c(1000000,5000000, 9000000)), variable = "pop")
summary(int_ape)
```


It's far better to use numbers relevant to the value/data that exists. We can use a bunch of summary statistics instead of just one to see the marginal effects of population. Turkey's 5 numbers include min, lower hinge, median, upper hinge and maximum - the function is called `fivenum()`

Looking at the marginal effects, you can see that the labor force participation of women is constant (as expected), but population marginal effects depend on the value of population - there seems to be a non-linear relationship.

```{r}
fivenum(wdi$pop, na.rm= TRUE)  # This is how to get the statistics

int_ape <- margins(int, at = list(pop =fivenum(wdi$pop, na.rm= TRUE)), variable= "pop") 

summary(int_ape)#integrated within margins command
```


And we can also graph the marginal effect of population with `cplot()`
```{r}
cplot(int, "pop", what = "effect", main = "Average Marginal Effect of Population")
```

### Stargazer (Again)

Let's show some models side by side

```{r}

library(stargazer)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

stargazer(ols, re, fe, type = "html", column.labels = c("OLS", "RE", "FE"), 
          model.names = FALSE, #remove model names
          dep.var.caption = "", #get rid of the dependent variable title at the top
          title = "Panel Data Results", #Have a title on your table
          covariate.labels = c("Edu", "lnPop", "Constant"), #rename variables to be cleaner
          omit = c("year"),  #omit the variables year from the output
         dep.var.labels   = "", #get rid of the dependent variable label
         model.numbers = FALSE, #get rid of model numbers
          add.lines=list(c("Time FE", "No", "Yes", "Yes")), # add a line/row for additional info (in this case about time fixed effects)
          notes= "Source: World Development Indicators Database", #add notes on the source of the data
          out = "panel_results.html" )#save the file in an output
```

Let's see how we can only show covariates of interest so that our table is reasonable.  

Here is the ugly table that you won't show me because it's unreasonable, right?

```{r}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

#long version 
fe_ols = lm(gdp~  edu + log(pop) +factor(country) +factor(year), data = wdi, na.action = na.omit)  ## Fixed effect(s)

fe_noyr <- plm(gdp ~ edu +log(pop) , data=wdi, index = c("iso2c"), model="within")

```

```{r}
# fe, fe_ols,fixed_tw are all different ways to produce the same exact results
stargazer(fe_noyr,fe, fe_ols, fixed_tw,
          type = "html", 
          column.labels = c("one-way FE", "FE plm", "FE dummies", "FE plm"), 
          model.names = FALSE,
          dep.var.caption = "",
          title = "Panel Data Results", 
          omit = c("country", "year"),  #So, if we want to remove the fixed effects or estimates, we can use the option, omit (another way to do this is keep, but that has issues with the constant) 
          covariate.labels = c("Edu", "lnPop", "Constant"),
          dep.var.labels   = "GDP per capita",
         add.lines=list(c("Time FE", "No", "Yes", "Yes", "Yes")),
          out = "panel_results_long.html")
          
#You can also use fixed est, but it doesn't play well with stargazer
fixed_est
```
## Time-Series Regressions

### Lags and Leads
Lags and leads are pretty straightforward to add to an OLS model

```{r}
lagols <-  lm(gdp~ lfpart_f + log(pop) + lag(log(pop) , n=1) +lag(log(pop), n = 2), data = wdi)
summary(lagols)

lagplm <-plm(gdp~ lfpart_f + log(pop) + lag(log(pop) , n=1) +lag(log(pop), n = 2), data = wdi, index = c("iso2c" ,"year"), ignorena = TRUE)
summary(lagplm)
```
Leads are similarly as easy....

```{r}
leadplm <-plm(gdp~ lfpart_f + log(pop) + lead(log(pop) , n=1) +lead(log(pop), n = 2), data = wdi, index = c("iso2c" ,"year"), ignorena = TRUE)
summary(leadplm)
```


### VAR

We will load our packages and then set the date column to a datetype so R knows that the column corresponds to a Date. It can be in any format, including quarters, so you just need to tell it what the format is. I have pulled this mostly for this [Towards Data Science blog] (https://towardsdatascience.com/a-deep-dive-on-vector-autoregression-in-r-58767ebb3f06). This [reference](https://www.econometrics-with-r.org/16.1-vector-autoregressions.html) may also be helpful.


```{r}
#loading all of the relevant packages
library(vars)
library(mFilter)
library(tseries)
library(TSstudio)
library(forecast)
library(vtable) 
```
```{r}
#getting VAR sample data
data <-read.csv("/Users/mkaltenberg/Documents/GitHub/Data_Analysis_Python_R/Advanced Regressions Stargazer/SampleVAR.csv")

#First, format the date column so R knows it's a date

data$date <- as.Date(data$date, format = "%m/%d/%y")

```


Next, you need to tell stata that the variables are time series and what frequency.

```{r}
#the data is quarterly, but the format of the date column is month day year. So, the frequency i 4.
gdp <- ts(data$real_gdp_growth, start = c(1999,2), frequency = 4)
psei <- ts(data$psei, start = c(1999,2), frequency = 4)
unem <- ts(data$unem, start = c(1999,2), frequency = 4)
bsp <- ts(data$bsp_rrp, start = c(1999,2), frequency = 4)

#We'll do this for each variable we want to follow over time
```

After declaring variables time series, you can do a lot of things much easier - run regressions or plot
```{r}
#pretty graphs
ts_plot(gdp)

```


Next, we'll bind the variables together to build our VAR model

```{r}
v1 <- cbind(gdp, bsp,psei, unem)
colnames(v1) <- cbind("GDP","BDP","PSEI", "UNEM")
```

Now, you need to figure out the number of lags

```{r}
lagselect <- VARselect(v1, lag.max = 15, type = "const")
```

And we estimate. Each equation represents an equation in the VAR system.

```{r}
Model1 <- VAR(v1, p = 2, type = "const", season = NULL, exog = NULL) 
summary(Model1)
```

You may want to do some testing, like for autocorrelation:

```{r}
Serial1 <- serial.test(Model1, lags.pt = 5, type = "PT.asymptotic")
Serial1

```
Granger Causality tests 

```{r}
Grangergdp<- causality(Model1, cause = "GDP")
Grangergdp

Grangerbdp<- causality(Model1, cause = "BDP")
Grangerbdp

Grangerpsei<- causality(Model1, cause = "PSEI")
Grangerpsei

Grangerunem<- causality(Model1, cause = "UNEM")
Grangerunem

```
Impulse Response Functions

```{r}
GDPirf <- irf(Model1, impulse = "GDP", response = "GDP", n.ahead = 20, boot = TRUE)
plot(GDPirf, ylab = "GDP", main = "GDP's shock to GDP")
```


ACF and PACEF Graphs

```{r}
acf (gdp, lag.max = 20, type = c("correlation", "covariance", "partial"), plot= TRUE,na.action = na.contiguous, demean = TRUE)
pacf (gdp, lag.max = 20, plot = TRUE, na.action = na.contiguous)
```

